---
languageName: "正體中文"
languageContribute: "幫助翻譯Rancher"

loggingPage:
  targetNav:
    experimental: 實驗性
    tips:
      caseA: 當前{pageScope}日誌收集未啟用。
      caseB: 當前日誌收集目標是<code class="text-capitalize">{currentTarget}</code>，點擊下面的保存按鈕將禁止當前{pageScope}的日誌收集。
      caseC: 當前日誌收集目標是<code class="text-capitalize">{currentTarget}</code>。
      caseD: 點擊下面的保存按鈕去設置<span class="text-info text-capitalize">{targetType}</span>為日誌收集目標服務。
      caseE: 點擊下面的保存按鈕來更新<span class="text-info text-capitalize">{targetType}</span>配置。
      caseF: 沒有日誌收集目標服務，完成以下設置並保存<code class="text-capitalize">{targetType}</code>為日誌收集目標服務。
  targetTypes:
    embedded: Embedded
    elasticsearch: Elasticsearch
    splunk: Splunk
    kafka: Kafka
    syslog: syslog
    disable: None
  endpoint: 訪問地址
  endpointPlaceholder: '例如: https://192.168.1.10:9200'
  logging: 日誌收集
  clusterHeader: 集群日誌收集
  projectHeader: 項目日誌收集
  helpText:
    cluster: 我們將為每個容器收集標準輸出和標準錯誤，<code>/var/log/containers/</code>是每個主機日誌文件路徑，日誌將被發送到您在下面選擇的目標服務。
    clusterTarget: 當前日誌收集目標是<code class="text-capitalize">{clusterTargetType}</code>。如果項目日誌收集啟用，日誌將被發送到集群目標和項目目標。
    noClusterTarget: 日誌收集默認禁用
  tags:
    keyPlaceholder: '例如: foo'
    valuePlaceholder: '例如: bar'
    addActionLabel: 添加字段
  keyValueForm:
    keyPlaceholder: '例如: 192.168.1.10'
  targetKafka:
    addActionLabel: 添加代理
    host: 主機
    port: 端口
  embedded:
    elasticsearchEndpoint: 'Elascticsearch Endpoint:'
    kibanaEndpoint: 'Kibana Endpoint:'
    header: 內置Elasticsearch配置
    failed: 失敗
    pending: 部署
    helpText:
      persistantStorage: 內置Elasticsearch是實驗性的，不會提供持久性存儲。
      requirements: 內置Elasticsearch包括Elasticsearch和Kibana，Elasticsearch在部署的節點上至少需要1個CPU和500M內存。
    cpuRequests:
      label: CPU需求(內核)
      placeholder: '例如: 1'
      helpText: 至少需要1個內核
    cpuLimits:
      label: CPU限制(內核)
      placeholder: '例如: 1'
      helpText: 至少需要1個內核
    memRequests:
      label: 內存需求(M)
      placeholder: '例如: 512M'
      helpText: 至少需要512M內存
    memLimits:
      label: 內存限制(M)
      placeholder: '例如: 2000'
      helpText: 至少需要512M內存
    resouceRequestsAndLimits: CPU和Memory

    indexPatterns:
      header: 索引模式
      helpText: 索引模式用於生成Elacticsearch索引
      prefix: 前綴
      prefixPlaceholder: '例如: logstash'
      dateFormat: '日期格式:'
    generatedIndex: '生成的索引格式為: <code class="text-italic">{esIndex}</code>，默認情況下索引模式為: $\{clusterName\}-$\{dateFormat\}'
  logPreview:
    header: 日誌格式預覽
  additional:
    header: 其他日誌配置
    fields:
      header: 自定義Log字段
      helpText: 以鍵值對的形式添加自定義字段，以便更好地進行過濾。
    flushInterval:
      header: 刷新時間間隔
      label: 刷新時間間隔
      placeholder: '例如: 1'
      sec: 秒
      helpText: 日誌刷新頻率.

  elasticsearch:
    header: Elasticsearch配置
    endpointHelpText: 輸入雲端Elacticsearch地址，或者私有部署的Elacticsearch地址。
    endpointProtocolError: Endpoint應該以"http://"或者"https://"開頭。
    endpointHostError: 請輸入主機名或域名。
    xpack:
      header: X-Pack安全
      headerOptional: (可選)
      helpText: 如果您的Elasticsearch開啟了X-Pack內置的本地身份驗證功能，請在下面設置用戶名和密碼。
      username: 用戶名
      usernamePlaceholder: '例如: John'
      password: 密碼
      passwordPlaceholder: 密碼
    indexPatterns:
      header: 索引模式
      helpText: 索引模式用於生成Elacticsearch索引。
      prefix: 前綴
      prefixPlaceholder: '例如: logstash'
      dateFormat: '日期格式:'
    generatedIndex: '生成的索引格式為: <code class="text-italic">{esIndex}</code>，默認情況下索引模式為: {indexFormat}。'
  splunk:
    header: Splunk HTTP事件收集配置
    helpText: '您可以找到如何配置Splunk HEC(HTTP事件收集器)的說明，<a href="http://docs.splunk.com/Documentation/Splunk/7.0.0/Data/UsetheHTTPEventCollector" target="_blank">點擊這裏</a>。'
    token: Token
    tokenPlaceholder: Your Token
    tokenHelpText: 'Token是允許日誌收集程序和HTTP客戶端連接到HEC的驗證信息，<a href="http://docs.splunk.com/Documentation/Splunk/7.0.0/Data/UsetheHTTPEventCollector#Configure_HTTP_Event_Collector_on_Splunk_Enterprise" target="_blank">了解詳情</a>。'
    source: 日誌源
    sourcePlaceholder: '例如: fluentd'
    sourceHelpText: '標識事件來源的默認字段，即事件發生的位置，<a href="https://docs.splunk.com/Splexicon:Source" target="_blank">了解詳情</a>。'
    index: Index
    indexPlaceholder: '例如: main'
    indexHelpText: '您在此處指定的索引必須在此令牌的允許索引列表中，<a href="https://docs.splunk.com/Splexicon:Index" target="_blank">了解詳情</a>。'
  kafka:
    header: Kafka配置
    endpointType: 訪問端點類型
    zookeeper: Zookeeper
    broker: Broker
    brokerTypeHelpText: 使用Zookeeper或Broker作為Kafka連接入口點。
    zookeeperHelpText: Zookeeper用於構建協調、配置管理、master檢測、檢測kafka集群中的節點更新。
    brokkerHelpText: Kafka集群由壹個或多個Broker組成，為每個Broker配置主機和端口。
    addEndpoint: 訪問地址
    topic: 主題
    topicPlaceholder: '例如: message'
    topicHelpText: 日誌將發送到這個主題。
  syslog:
    endpointPlaceholder: '例如: 192.168.1.10:514'
    header: Syslog配置
    endpointHelpText: 在這裏輸入日誌服務器的接入地址，選擇TCP將顯示SSL證書配置。
    program: 程序名稱
    programPlaceholder: '例如: MyProgram'
    programHelpText: 日誌中的程序名稱。
    severityHelpText: '<p class="text-info text-small">日誌的嚴重性列表可以在這裏找到，<a href="https://tools.ietf.org/html/rfc5424#section-6.2.1" target="_blank">了解詳情</a>。</p>'
    severities:
      emergency: Emergency
      alert: alert
      critical: Ctitical
      error: error
      warning: warning
      notice: notice
      info: Info
      debug: Debug
    tokenHelpText: '將令牌添加到每個系統日誌消息的結構化數據中。對於像<a href="https://help.sumologic.com/Send-Data/Sources/02Sources-for-Hosted-Collectors/Cloud-Syslog-Source" target="_blank">Sumologic</a>，<a href="https://www.loggly.com/docs/customer-token-authentication-token" target="_blank">Loggly</a>等這樣的雲日誌系統，您可以在其配置頁面上生成令牌。'
  ssl:
    sslHeader: SSL配置
    certificate:
      label: 可信服務器證書
    clientKey:
      label: 客戶端私鑰
    clientCert:
      label: 客戶端證書
    clientKeyPass:
      label: 客戶端私鑰密碼
      password:
        placeholder: 客戶端私鑰密碼
    verify:
      label: SSL校驗
      enabled: 'Enabled - 輸入可信服務器證書'
      disabled: Disabled
  dockerRootDir:
    header: Docker配置
    label: Docker Root Directory
    placeholder: "輸入docker root Directory，默認值為{dir}"
